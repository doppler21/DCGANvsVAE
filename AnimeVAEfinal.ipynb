{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AnimeVAEfinal.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W0f76PCpRNx",
        "colab_type": "code",
        "outputId": "1ec39a76-f913-4af6-8410-67d02625c14d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "from google.colab import files\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEz8qfAvplN4",
        "colab_type": "code",
        "outputId": "f26f09c8-7ee5-4a7e-faa1-dbbbd1f0cdfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUTLvbWkpmKq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile(\"/content/gdrive/My Drive/anime-faces.zip\", 'r')\n",
        "zip_ref.extractall(\"/content/data\")\n",
        "zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHaWRfYKqAge",
        "colab_type": "code",
        "outputId": "4c95ef80-4444-448c-d423-70e9cfe8251c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import os\n",
        "from skimage.transform import rescale\n",
        "from skimage.transform import resize\n",
        "list_file1 = os.listdir('data/data')\n",
        "print(len(list_file1))\n",
        "list_file = []\n",
        "for i in list_file1:\n",
        "    name_length = len(i)\n",
        "    if(i[name_length-1]==\"g\"):\n",
        "        list_file.append(i)\n",
        "        \n",
        "print(len(list_file))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21552\n",
            "21551\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZuF9MxZqNno",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from skimage.io import imread\n",
        "data_train_gan = np.array([resize(imread(os.path.join('data/data',file_name)), (64, 64)) for file_name in list_file])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkzhqY3zqbIk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_params = 0.0005\n",
        "epochs = 50000\n",
        "batch_size = 64\n",
        "\n",
        "image_dim = 64*64*3\n",
        "neural_network_dim = 4096\n",
        "latent_variable_dim = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2DAAoB0rnCJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def xavier(in_shape):\n",
        "  val = tf.random_normal(shape = in_shape, stddev = 1./tf.sqrt(in_shape[0]/2.))\n",
        "  return (val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PK9QujpErpj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Weight = { \"weight_matrix_encoder_hidden\": tf.Variable(xavier([image_dim, neural_network_dim])),\n",
        "           \"weight_mean_hidden\": tf.Variable(xavier([neural_network_dim, latent_variable_dim])),\n",
        "           \"weight_std_hidden\": tf.Variable(xavier([neural_network_dim, latent_variable_dim])),\n",
        "           \"weight_matrix_decoder_hidden\": tf.Variable(xavier([latent_variable_dim, neural_network_dim])),\n",
        "           \"weight_decoder\": tf.Variable(xavier([neural_network_dim, image_dim]))\n",
        "         }\n",
        "\n",
        "Bias = { \"bias_matrix_encoder_hidden\": tf.Variable(xavier([neural_network_dim])),\n",
        "         \"bias_mean_hidden\": tf.Variable(xavier([latent_variable_dim])),\n",
        "         \"bias_std_hidden\": tf.Variable(xavier([latent_variable_dim])),\n",
        "         \"bias_matrix_decoder_hidden\": tf.Variable(xavier([neural_network_dim])),\n",
        "         \"bias_decoder\": tf.Variable(xavier([image_dim]))\n",
        "       }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdEcTIryrrfk",
        "colab_type": "code",
        "outputId": "85c28035-891e-46a4-9518-8d709985bef1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "#Encoder section\n",
        "image_x = tf.placeholder(tf.float32, shape=[None, image_dim])\n",
        "\n",
        "Encoder_layer = tf.add(tf.matmul(image_x, Weight[\"weight_matrix_encoder_hidden\"]), Bias[\"bias_matrix_encoder_hidden\"])\n",
        "Encoder_layer = tf.nn.tanh(Encoder_layer)\n",
        "\n",
        "Mean_layer = tf.add(tf.matmul(Encoder_layer, Weight[\"weight_mean_hidden\"]), Bias[\"bias_mean_hidden\"])\n",
        "Standard_deviation_layer = tf.add(tf.matmul(Encoder_layer, Weight[\"weight_std_hidden\"]), Bias[\"bias_std_hidden\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-3493d30d9bbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimage_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimage_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mEncoder_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWeight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"weight_matrix_encoder_hidden\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBias\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bias_matrix_encoder_hidden\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mEncoder_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEncoder_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'flatten' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gfLf0Xqrt_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reparametrization Trick\n",
        "epsilon = tf.random_normal(tf.shape(Standard_deviation_layer), dtype=tf.float32, mean=0.0, stddev = 1.0)\n",
        "latent_layer = Mean_layer + tf.exp(0.5*Standard_deviation_layer)*epsilon"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AK149NY8rvuj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Decoder Layer\n",
        "Decoder_hidden = tf.add(tf.matmul(latent_layer, Weight[\"weight_matrix_decoder_hidden\"]), Bias[\"bias_matrix_decoder_hidden\"])\n",
        "Decoder_hidden = tf.nn.tanh(Decoder_hidden)\n",
        "\n",
        "Decoder_output_layer = tf.add(tf.matmul(Decoder_hidden, Weight[\"weight_decoder\"]), Bias[\"bias_decoder\"])\n",
        "Decoder_output_layer = tf.nn.sigmoid(Decoder_output_layer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAwNDkggrxpK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_function(original_image, reconstructed_image):\n",
        "\n",
        "  #Reconstruction loss\n",
        "  data_fidelity_loss = original_image*tf.log(1e-10 + reconstructed_image) + (1-original_image)*tf.log(1e-10 + 1-reconstructed_image)\n",
        "  data_fidelity_loss = -tf.reduce_sum(data_fidelity_loss,1)\n",
        "\n",
        "  #KL Divergence Loss\n",
        "  KL_div_loss = 1 + Standard_deviation_layer - tf.square(Mean_layer) - tf.exp(Standard_deviation_layer)\n",
        "  KL_div_loss = -0.5*tf.reduce_sum(KL_div_loss,1)\n",
        "  \n",
        "  network_loss = tf.reduce_mean(data_fidelity_loss + KL_div_loss)\n",
        "  return network_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJCKpJDHrznQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_value = loss_function(image_x, Decoder_output_layer)\n",
        "optimizer = tf.train.RMSPropOptimizer(learning_params).minimize(loss_value)\n",
        "\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-RqOQwur3cK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess.close()\n",
        "sess = tf.Session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7i0xhMKcr7Gj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess.run(init)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUPf6GI0r85x",
        "colab_type": "code",
        "outputId": "53eecfe4-f8b6-4f72-d9b7-c7300a982ac2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "start = 0\n",
        "\n",
        "for i in range(epochs):\n",
        "  stop = start + batch_size\n",
        "  x_batch = data_train_gan[start: stop]\n",
        "  for i in x_batch:\n",
        "    i.flatten()\n",
        "  _, loss = sess.run([optimizer, loss_value], feed_dict = {image_x : x_batch})\n",
        "  start += batch_size\n",
        "  if i%10 == 0:\n",
        "    print(\"loss is {0} at iteration {1}\".format(loss,i))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-a77e79572f01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_value\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mimage_x\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mstart\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1154\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m                 (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m   1157\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (64, 64, 64, 3) for Tensor 'Placeholder_1:0', which has shape '(?, 12288)'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7f1ohXhdsILo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}